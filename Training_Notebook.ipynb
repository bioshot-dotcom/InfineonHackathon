{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jMqOF9jVc5S6",
        "xV8izcOHC1xu",
        "I0TTPwV8MoXa",
        "pChfc38v_bYB",
        "QI4McqhNywuQ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Infineon Hackaton"
      ],
      "metadata": {
        "id": "MoKzZbn643_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sync data with google drive"
      ],
      "metadata": {
        "id": "yWRRZLjQ5ACB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54cDLhV0zoYO",
        "outputId": "5ff9ebb3-5555-4088-ecfe-4bf74bbce022"
      },
      "source": [
        "#We will load the data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "SEED = 1234"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_sendx = xtestfinalgg[1:50, ...]\n",
        "to_sendy = ytestfinalgg[1:50, ...]"
      ],
      "metadata": {
        "id": "CIyncP2lbG5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.save(\"/content/drive/MyDrive/Challenge2/sendx\", to_sendx)\n",
        "np.save(\"/content/drive/MyDrive/Challenge2/sendy\", to_sendy)"
      ],
      "metadata": {
        "id": "EPjUaVF2cLWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and preprocess data\n",
        "\n",
        "The data was collected during the hackaton. We created 3 different environments each with 4 classes ( number of people, 0, 1, 2, 3 ).\n",
        "All the files are on drive. If you want to use the data please ask us to provide you the link"
      ],
      "metadata": {
        "id": "usxcG22tCDOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BCL environments"
      ],
      "metadata": {
        "id": "igiNjGW0DCcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import os \n",
        "\n",
        "\n",
        "# This file is on drive. If tou want to use it plead ask us to provide you the link\n",
        "open_file = open(\"/content/drive/MyDrive/sample.pkl\", \"rb\")\n",
        "loaded_list = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "array_loaded = np.array(loaded_list)\n",
        "array_loaded.shape\n",
        "from numpy import moveaxis\n",
        "gg = moveaxis(array_loaded, 1, 3)\n",
        "gg.shape"
      ],
      "metadata": {
        "id": "ZT8Uq9nNawhd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb65696e-c13f-4799-c9d0-e7118f5ced96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Deleting unused objects \n",
        "array_loaded = None\n",
        "loaded_list = None "
      ],
      "metadata": {
        "id": "hxDUOqFU4EXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels\n",
        "target_2 = [0] * 3000\n",
        "target_2.extend([1]*3000)\n",
        "target_2.extend([2]*3000)\n",
        "target_2.extend([3]*3000)\n",
        "target_2 = np.array(target_2)"
      ],
      "metadata": {
        "id": "ikw5aICXcwuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nave"
      ],
      "metadata": {
        "id": "QMZMoblMECOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions from infineon to preprocess the raw data"
      ],
      "metadata": {
        "id": "eVnnSASlE8X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, Optional\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def range_fft(x: np.ndarray,\n",
        "              window: Optional[Callable[[int], np.ndarray]] = None,\n",
        "              remove_mean: bool = True) -> np.ndarray:\n",
        "    \"\"\"Apply a Range FFT.\n",
        "\n",
        "    Args:\n",
        "        x: Raw radar data of shape [..., n_samples].\n",
        "        window: Window function for Range FFT. If None, no window is applied. Otherwise, the given window\n",
        "            function is applied. (Default: None)\n",
        "        remove_mean: If True, remove mean along samples dimension. (Default: True)\n",
        "\n",
        "    Returns:\n",
        "        Transformed range data of shape [..., n_range].\n",
        "\n",
        "    Examples:\n",
        "        Dummy data: 10 frames, 3 antennas, 64 chirps, 128 samples.\n",
        "\n",
        "        >>> raw_data = np.random.rand(10,3,64,128)\n",
        "        >>> range_data = range_fft(raw_data)\n",
        "\n",
        "        Use window function. (Available in `scipy https://docs.scipy.org/doc/scipy/reference/signal.windows.html`)\n",
        "\n",
        "        >>> from scipy import signal\n",
        "        >>> range_data = range_fft(raw_data, signal.windows.blackman)\n",
        "\n",
        "        If window function uses additional parameters you can wrap it with lambda.\n",
        "\n",
        "        >>> range_window_func = lambda x: signal.windows.chebwin(x, at=100)\n",
        "        >>> range_data = range_fft(raw_data, range_window_func)\n",
        "\n",
        "    See Also:\n",
        "        :func:`doppler_fft`: Apply a Doppler FFT.\n",
        "    \"\"\"\n",
        "    n_samples = x.shape[-1]\n",
        "\n",
        "    if remove_mean:\n",
        "        x = x - x.mean(axis=-1, keepdims=True)\n",
        "\n",
        "    if window is not None:\n",
        "        w_array = window(n_samples)\n",
        "        w_array /= w_array.sum()  # Normalize window\n",
        "        x = x * w_array[(x.ndim - 1) * (None,) + (slice(None),)]\n",
        "    x_range = np.fft.fft(x, axis=-1)  # Range FFT\n",
        "    x_range = x_range[..., :n_samples // 2]  # Real data is symmetric\n",
        "\n",
        "    return x_range\n",
        "\n",
        "\n",
        "def doppler_fft(x: np.ndarray,\n",
        "                window: Optional[Callable[[int], np.ndarray]] = None) -> np.ndarray:\n",
        "    \"\"\"Apply a Doppler FFT.\n",
        "\n",
        "    Args:\n",
        "        x: Range data of shape [..., n_chirps, n_range].\n",
        "        window: Window function for Doppler FFT. If None, no window is applied. Otherwise, the given window\n",
        "            function is applied.\n",
        "\n",
        "    Returns:\n",
        "        Transformed range doppler data of shape [..., n_doppler, n_range].\n",
        "\n",
        "    Examples:\n",
        "        Dummy data: 10 frames, 3 antennas, 64 chirps, 128 range samples.\n",
        "\n",
        "        >>> range_data = np.random.rand(10,3,64,128)\n",
        "        >>> doppler_data = doppler_fft(range_data)\n",
        "\n",
        "        Use window function. (Available in `scipy https://docs.scipy.org/doc/scipy/reference/signal.windows.html`)\n",
        "\n",
        "        >>> from scipy import signal\n",
        "        >>> doppler_data = doppler_fft(range_data, signal.windows.blackman)\n",
        "\n",
        "        If window function uses additional parameters you can wrap it with lambda.\n",
        "\n",
        "        >>> doppler_window_func = lambda x: signal.windows.chebwin(x, at=100)\n",
        "        >>> doppler_data  = doppler_fft(range_data, doppler_window_func)\n",
        "\n",
        "    See Also:\n",
        "        :func:`range_fft`: Apply a Range FFT.\n",
        "    \"\"\"\n",
        "    n_chirps = x.shape[-2]\n",
        "\n",
        "    if window is not None:\n",
        "        w_array = window(n_chirps)\n",
        "        w_array /= w_array.sum()  # Normalize window\n",
        "        x = x * w_array[(x.ndim - 2) * (None,) + (slice(None), None)]\n",
        "    x_rdi = np.fft.fft(x, axis=-2)  # Doppler FFT\n",
        "    x_rdi = np.fft.fftshift(x_rdi, axes=-2)  # Swap spectrum\n",
        "\n",
        "    return x_rdi\n",
        "\n",
        "\n",
        "def range_doppler_fft(x: np.ndarray,\n",
        "                      range_window: Optional[Callable[[\n",
        "                          int], np.ndarray]] = None,\n",
        "                      doppler_window: Optional[Callable[[\n",
        "                          int], np.ndarray]] = None,\n",
        "                      remove_mean: bool = True) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generate a Range Doppler Response.\n",
        "\n",
        "    Args:\n",
        "        x: Raw radar data of shape [..., n_chirps, n_samples].\n",
        "        range_window: Window function for Range FFT. If None, no window is applied. Otherwise, the given window\n",
        "            function is applied. (Default: None)\n",
        "        doppler_window: Window function for Doppler FFT. If None, no window is applied. Otherwise, the given window\n",
        "            function is applied. (Default: None)\n",
        "        remove_mean: If True, remove mean along samples dimension. (Default: True)\n",
        "\n",
        "    Returns:\n",
        "        Transformed range data of shape [..., n_doppler, n_range].\n",
        "\n",
        "    Examples:\n",
        "        Dummy data: 10 frames, 3 antennas, 64 chirps, 128 samples.\n",
        "\n",
        "        >>> raw_data = np.random.rand(10,3,64,128)\n",
        "        >>> rdi = range_doppler_fft(raw_data)\n",
        "\n",
        "        Use window function. (Available in `scipy https://docs.scipy.org/doc/scipy/reference/signal.windows.html`)\n",
        "\n",
        "        >>> from scipy import signal\n",
        "        >>> rdi = range_doppler_fft(raw_data, signal.windows.blackman, signal.windows.blackman)\n",
        "\n",
        "        If window function uses additional parameters you can wrap it with lambda.\n",
        "\n",
        "        >>> range_window_func = signal.windows.blackman\n",
        "        >>> doppler_window_func = lambda x: signal.windows.chebwin(x, at=100)\n",
        "        >>> rdi  = range_doppler_fft(raw_data, range_window_func, doppler_window_func)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    x_range = range_fft(x, range_window, remove_mean)\n",
        "    x_rdi = doppler_fft(x_range, doppler_window)\n",
        "\n",
        "    return x_rdi\n",
        "\n",
        "def processing_rangeDopplerData(st_data, compensateMotion=False):\n",
        "\n",
        "\n",
        "    range_doppler_data = range_doppler_fft(st_data)\n",
        "\n",
        "    return range_doppler_data\n",
        "\n",
        "import tensorflow as tf\n",
        "import os \n",
        "import numpy as np\n",
        "\n",
        "def processing_rangeDopplerData(st_data, compensateMotion=False):\n",
        "    range_doppler_data = range_doppler_fft(st_data)\n",
        "    return range_doppler_data\n"
      ],
      "metadata": {
        "id": "ruQWpuzJEXXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are loading our data from the Nave environment"
      ],
      "metadata": {
        "id": "8BSlNnwFFVaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = np.load('/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c3.npy')\n",
        "range_doppler_map3 = processing_rangeDopplerData(data3)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "# The shape of the radar data depends on the radar settings.\n",
        "# The different dimensions of the shape are (frame_index, receiver_index, chirp_index, sample_index).\n",
        " \n",
        "data2 = np.load('/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c2.npy')\n",
        "range_doppler_map2 = processing_rangeDopplerData(data2)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "data10 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c1e0.npy\")\n",
        "range_doppler_map10 = processing_rangeDopplerData(data10)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        "data11 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c1e1.npy\")\n",
        "range_doppler_map11 = processing_rangeDopplerData(data11)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        "data12 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c1e2.npy\")\n",
        "range_doppler_map12 = processing_rangeDopplerData(data12)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "data00 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c0e0.npy\")\n",
        "range_doppler_map00 = processing_rangeDopplerData(data00)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        "data01 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c0e1.npy\")\n",
        "range_doppler_map01 = processing_rangeDopplerData(data01)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        "data02 = np.load(\"/content/drive/MyDrive/Challenge2/acquisizioni_nave/nave_raw_data_c0e2.npy\")\n",
        "range_doppler_map02 = processing_rangeDopplerData(data02)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        " \n",
        "data_to_append = []\n",
        " \n",
        "def create_2d_image(c1, c2, c3):\n",
        "    return np.vstack([np.expand_dims(c1, axis=0), np.expand_dims(c2, axis=0), np.expand_dims(c3, axis=0)])\n",
        " \n",
        "for i in range(data00.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map00[i, 0, ...], range_doppler_map00[i, 1, ...], range_doppler_map00[i, 2, ...]))\n",
        "for i in range(data01.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map01[i, 0, ...], range_doppler_map01[i, 1, ...], range_doppler_map01[i, 2, ...]))\n",
        "for i in range(data02.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map02[i, 0, ...], range_doppler_map02[i, 1, ...], range_doppler_map02[i, 2, ...]))\n",
        "for i in range(data10.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map10[i, 0, ...], range_doppler_map10[i, 1, ...], range_doppler_map10[i, 2, ...]))\n",
        "for i in range(data11.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map11[i, 0, ...], range_doppler_map11[i, 1, ...], range_doppler_map11[i, 2, ...]))\n",
        "for i in range(data12.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map12[i, 0, ...], range_doppler_map12[i, 1, ...], range_doppler_map12[i, 2, ...]))\n",
        "for i in range(data2.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map2[i, 0, ...], range_doppler_map2[i, 1, ...], range_doppler_map2[i, 2, ...]))\n",
        "for i in range(data3.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map3[i, 0, ...], range_doppler_map3[i, 1, ...], range_doppler_map3[i, 2, ...]))\n",
        "\n",
        "\n",
        "array_loaded = np.array(data_to_append)\n",
        "array_loaded.shape\n",
        "from numpy import moveaxis\n",
        "ggirenave = moveaxis(array_loaded, 1, 3)\n",
        "ggirenave.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDa1b7AYFMDr",
        "outputId": "60fb0f3f-d653-4c96-f7f2-c02b7114d9ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_loaded = None\n",
        "loaded_list = None \n",
        "data00 = None\n",
        "data01 = None\n",
        "data02 = None\n",
        "data10 = None\n",
        "data11 = None\n",
        "data12 = None\n",
        "data2 = None\n",
        "data3 = None\n",
        "range_doppler_map3=None\n",
        "range_doppler_map2=None\n",
        "range_doppler_map00=None\n",
        "range_doppler_map01=None\n",
        "range_doppler_map02=None\n",
        "range_doppler_map10=None\n",
        "range_doppler_map11=None\n",
        "range_doppler_map12=None\n",
        "data_to_append=None"
      ],
      "metadata": {
        "id": "xGLSOeCKG5HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ED 16"
      ],
      "metadata": {
        "id": "pDc50TPqGULH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = np.load(\"/content/drive/MyDrive/Challenge2/ed16/ed16_raw_data_c3.npy\")\n",
        "range_doppler_map3 = processing_rangeDopplerData(data3)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "# The shape of the radar data depends on the radar settings.\n",
        "# The different dimensions of the shape are (frame_index, receiver_index, chirp_index, sample_index).\n",
        " \n",
        "data2 = np.load(\"/content/drive/MyDrive/Challenge2/ed16/ed16_raw_data_c2.npy\")\n",
        "range_doppler_map2 = processing_rangeDopplerData(data2)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "data1 = np.load(\"/content/drive/MyDrive/Challenge2/ed16/ed16_raw_data_c1.npy\")\n",
        "range_doppler_map1 = processing_rangeDopplerData(data1)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        "data0 = np.load(\"/content/drive/MyDrive/Challenge2/ed16/ed16_raw_data_c0.npy\")\n",
        "range_doppler_map0 = processing_rangeDopplerData(data0)\n",
        "print(\"(frame_index, receiver_index, chirp_index, sample_index)\")\n",
        " \n",
        " \n",
        "data_to_append = []\n",
        " \n",
        "def create_2d_image(c1, c2, c3):\n",
        "    return np.vstack([np.expand_dims(c1, axis=0), np.expand_dims(c2, axis=0), np.expand_dims(c3, axis=0)])\n",
        " \n",
        "for i in range(data0.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map0[i, 0, ...], range_doppler_map0[i, 1, ...], range_doppler_map0[i, 2, ...]))\n",
        " \n",
        "for i in range(data1.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map1[i, 0, ...], range_doppler_map1[i, 1, ...], range_doppler_map1[i, 2, ...]))\n",
        " \n",
        "for i in range(data2.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map2[i, 0, ...], range_doppler_map2[i, 1, ...], range_doppler_map2[i, 2, ...]))\n",
        " \n",
        "for i in range(data3.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map3[i, 0, ...], range_doppler_map3[i, 1, ...], range_doppler_map3[i, 2, ...]))\n",
        "\n",
        "\n",
        "array_loaded = np.array(data_to_append)\n",
        "array_loaded.shape\n",
        "from numpy import moveaxis\n",
        "gged16 = moveaxis(array_loaded, 1, 3)\n",
        "gged16.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ec61fd-a230-425c-dc13-da6d4cb0d3f7",
        "id": "NchNxSbbIlOi"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n",
            "(frame_index, receiver_index, chirp_index, sample_index)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array_loaded = None\n",
        "data0 = None\n",
        "data1 = None\n",
        "data2 = None\n",
        "data3 = None\n",
        "range_doppler_map3=None\n",
        "range_doppler_map2=None\n",
        "range_doppler_map0=None\n",
        "range_doppler_map1=None\n",
        "data_to_append=None"
      ],
      "metadata": {
        "id": "i1gbvyeVI0-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Building \n",
        "\n",
        "We use a CNN to classify each frame from the data gathered from the infineon sensor. The inputs are the frames read by the 3 antennas of our sensor. We create an RGB image by using for each antenna the respective frame. The final dimension of our input is (64, 64, 3). Where 3 is the number of channels"
      ],
      "metadata": {
        "id": "JFISMrlyI2sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use transfer learning by using a pretrained network (EfficienNetV2L) and we train the layers starting from the 700th position. We got a total number of parameters of 64 M parameters"
      ],
      "metadata": {
        "id": "NKewQCshKSXM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EdVj9o7z5sU"
      },
      "source": [
        "xception = tf.keras.applications.EfficientNetV2L(include_top=False,\n",
        "                                            weights='imagenet',\n",
        "                                            input_shape=(64, 64, 3))\n",
        "\n",
        "xception.trainable = True\n",
        "\n",
        "\n",
        "\n",
        "for i in range(700):\n",
        "  xception.layers[i].trainable = False\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(xception)\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "model.add(tf.keras.layers.Dense(units=4, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "# Loss\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# learning rate\n",
        "lr = 3e-3     \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# -------------------\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "metrics = [\"accuracy\"]\n",
        "# ------------------\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "ATr82Q_XKycn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "We concatenate all the data from the 3 different environments to have a unique dataset. This will surely improve the generalization in other types of environments. Only indoor since the owners told us the only indoor environments is our target"
      ],
      "metadata": {
        "id": "zi5ru0rALiqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtraingg, xtestgg, ytraingg, ytestgg = train_test_split(gg, target_2, test_size=0.2, stratify=target_2, random_state=0)\n",
        "xtrainggire, xtestggire, ytrainggire, ytestggire = train_test_split(ggirenave, target_2, test_size=0.2, stratify=target_2, random_state=0)\n",
        "xtraingged16, xtestgged16, ytraingged16, ytestgged16 = train_test_split(gged16, target_2, test_size=0.2, stratify=target_2, random_state=0)"
      ],
      "metadata": {
        "id": "LYL5EoJUMH1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gg = None\n",
        "ggirenave = None \n",
        "gged16 = None"
      ],
      "metadata": {
        "id": "4E9T07zKMH1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrainfinalgg = np.concatenate((xtraingg,xtrainggire,xtraingged16))\n",
        "xtestfinalgg=np.concatenate((xtestgg,xtestggire,xtestgged16))\n",
        "ytrainfinalgg = np.concatenate((ytraingg,ytrainggire,ytraingged16))\n",
        "ytestfinalgg=np.concatenate((ytestgg,ytestggire,ytestgged16))"
      ],
      "metadata": {
        "id": "j1ccNxYoMH1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xtrainggire=None\n",
        "xtestggire=None \n",
        "ytrainggire=None \n",
        "ytestggire=None\n",
        "xtraingg=None\n",
        "xtestgg=None \n",
        "ytraingg=None \n",
        "ytestgg=None\n",
        "xtraingged16=None\n",
        "xtestgged16=None \n",
        "ytraingged16=None \n",
        "ytestgged16=None"
      ],
      "metadata": {
        "id": "b3u_LdjCMH1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qerC4cK50dli"
      },
      "source": [
        "import tensorflow as tf\n",
        "callbacks = []\n",
        "ckpt_dir = '/content/drive/MyDrive/Challenge2'\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt)'), \n",
        "                                                   save_weights_only=True,\n",
        "                                                   save_best_only=True,\n",
        "                                                   monitor='val_accuracy',\n",
        "                                                   mode='max') # False to save the model directly) # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "#es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=8)  #The first run was with val loss\n",
        "\n",
        "#callbacks.append(es_callback)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6iwfnfw8GSEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "uFsPcK-c0I_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x=xtrainfinalgg,  y=ytrainfinalgg,             ##Quello sotto rappresenta l'allenamento finale \n",
        "          epochs=100,  #### set repeat in traitning dataset\n",
        "          validation_data=(xtestfinalgg, ytestfinalgg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qjowqf5_t4xO",
        "outputId": "361ddaa6-44f6-44e7-fb2e-fe7b6f803124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "900/900 [==============================] - 175s 158ms/step - loss: 0.6178 - accuracy: 0.7275 - val_loss: 0.8702 - val_accuracy: 0.6601\n",
            "Epoch 2/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.4231 - accuracy: 0.8206 - val_loss: 0.4647 - val_accuracy: 0.8168\n",
            "Epoch 3/100\n",
            "900/900 [==============================] - 140s 155ms/step - loss: 0.3536 - accuracy: 0.8509 - val_loss: 0.3602 - val_accuracy: 0.8465\n",
            "Epoch 4/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.3256 - accuracy: 0.8689 - val_loss: 0.4444 - val_accuracy: 0.8254\n",
            "Epoch 5/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.2883 - accuracy: 0.8848 - val_loss: 0.3028 - val_accuracy: 0.8783\n",
            "Epoch 6/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.2645 - accuracy: 0.8928 - val_loss: 0.2931 - val_accuracy: 0.8786\n",
            "Epoch 7/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.2553 - accuracy: 0.8988 - val_loss: 0.2519 - val_accuracy: 0.9015\n",
            "Epoch 8/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.2390 - accuracy: 0.9048 - val_loss: 0.2922 - val_accuracy: 0.8875\n",
            "Epoch 9/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.2224 - accuracy: 0.9112 - val_loss: 0.2613 - val_accuracy: 0.8949\n",
            "Epoch 10/100\n",
            "900/900 [==============================] - 140s 155ms/step - loss: 0.2106 - accuracy: 0.9166 - val_loss: 0.3255 - val_accuracy: 0.8714\n",
            "Epoch 11/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1987 - accuracy: 0.9202 - val_loss: 0.2454 - val_accuracy: 0.9057\n",
            "Epoch 12/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1906 - accuracy: 0.9254 - val_loss: 0.2383 - val_accuracy: 0.9057\n",
            "Epoch 13/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1834 - accuracy: 0.9268 - val_loss: 0.2585 - val_accuracy: 0.9014\n",
            "Epoch 14/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1719 - accuracy: 0.9316 - val_loss: 0.2386 - val_accuracy: 0.9054\n",
            "Epoch 15/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1628 - accuracy: 0.9362 - val_loss: 0.3051 - val_accuracy: 0.8843\n",
            "Epoch 16/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1579 - accuracy: 0.9368 - val_loss: 0.2950 - val_accuracy: 0.9006\n",
            "Epoch 17/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.1513 - accuracy: 0.9403 - val_loss: 0.2415 - val_accuracy: 0.9153\n",
            "Epoch 18/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.1489 - accuracy: 0.9422 - val_loss: 0.2737 - val_accuracy: 0.9071\n",
            "Epoch 19/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.1371 - accuracy: 0.9457 - val_loss: 0.2261 - val_accuracy: 0.9190\n",
            "Epoch 20/100\n",
            "900/900 [==============================] - 140s 156ms/step - loss: 0.1300 - accuracy: 0.9502 - val_loss: 0.2379 - val_accuracy: 0.9174\n",
            "Epoch 21/100\n",
            "900/900 [==============================] - 140s 156ms/step - loss: 0.1276 - accuracy: 0.9489 - val_loss: 0.2312 - val_accuracy: 0.9185\n",
            "Epoch 22/100\n",
            "900/900 [==============================] - 139s 154ms/step - loss: 0.1234 - accuracy: 0.9525 - val_loss: 0.2382 - val_accuracy: 0.9128\n",
            "Epoch 23/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.3271 - val_accuracy: 0.8936\n",
            "Epoch 24/100\n",
            "900/900 [==============================] - 139s 155ms/step - loss: 0.1122 - accuracy: 0.9563 - val_loss: 0.2457 - val_accuracy: 0.9143\n",
            "Epoch 25/100\n",
            "417/900 [============>.................] - ETA: 1:05 - loss: 0.1100 - accuracy: 0.9552"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f4535248fcd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(x=xtrainfinalgg,  y=ytrainfinalgg,             ##Quello sotto rappresenta l'allenamento finale \n\u001b[1;32m      2\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m#### set repeat in traitning dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m           validation_data=(xtestfinalgg, ytestfinalgg))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3lORLSwW415y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model"
      ],
      "metadata": {
        "id": "KOCjOujt9q8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"/content/drive/MyDrive/Challenge2/checkpoint\")"
      ],
      "metadata": {
        "id": "cg2Y9CRM72ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "sGgtsJLk9vpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = np.load(\"/content/drive/MyDrive/Challenge2/ed16/ed16_raw_data_c3.npy\")\n",
        "range_doppler_map_new = processing_rangeDopplerData(data_new)\n",
        "data_to_append_new = []\n",
        " \n",
        "def create_2d_image(c1, c2, c3):\n",
        "    return np.vstack([np.expand_dims(c1, axis=0), np.expand_dims(c2, axis=0), np.expand_dims(c3, axis=0)])\n",
        "for i in range(data_new.shape[0]):\n",
        "    data_to_append.append(create_2d_image(range_doppler_map_new[i, 0, ...], range_doppler_new[i, 1, ...], range_doppler_new[i, 2, ...]))\n",
        "\n",
        "array_loaded_new = np.array(data_to_append_new)\n",
        "array_loaded_new.shape\n",
        "from numpy import moveaxis\n",
        "gg_new = moveaxis(array_loaded_new, 1, 3)\n",
        "gg_new.shape"
      ],
      "metadata": {
        "id": "e-mCOSl7Eh82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predictions = model.predict(xtestfinalgg)\n",
        "predictions = np.argmax(predictions, axis=1)\n",
        "cf = confusion_matrix(ytestfinalgg, predictions, normalize='true')"
      ],
      "metadata": {
        "id": "LCIvaUpsjInx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "cf = confusion_matrix(ytestfinalgg, predictions, normalize='true')\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cf,display_labels=[\"0\",\"1\",\"2\",\"3\"])\n",
        "disp.plot(cmap=plt.cm.Greys)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "6VRDFsCzj8Gt",
        "outputId": "918e1e8c-863c-43b1-d34e-ab7d95add0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f11ef8e2fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}